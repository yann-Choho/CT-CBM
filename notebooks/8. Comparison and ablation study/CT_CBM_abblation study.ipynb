{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0745a076-0599-4a14-a5ff-3e1b0ab4d383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# CT-CBM \n",
    "\n",
    "---\n",
    "Goal of the notebook: .\n",
    "\n",
    "Inputs of the notebook:\n",
    "- \n",
    "\n",
    "Output of the notebook:\n",
    "- prediction + interpretation layer for text classification.\n",
    "\n",
    "\n",
    "Takeaways: \n",
    "- .\n",
    "- ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5b14703-f14b-46cf-af06-cc4193b66bd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61184a1f-5298-493b-bf64-b31f6b8d93ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../run_experiments/')\n",
    "sys.path.append('../../run_experiments/scripts')\n",
    "sys.path.append('../../run_experiments/models')\n",
    "sys.path.append('../../run_experiments/data')\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "\n",
    "# model for CBM\n",
    "# import fonction for getting PLM and tokenizer\n",
    "from models.utils import load_model_and_tokenizer\n",
    "\n",
    "from concepts_discovery_utils import extract_target_words, create_context_window, load_model, run_concepts_discovery\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32e801e0-ef91-415b-bb0d-30d14bb5e61f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Delete awkward warning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4447ea53-7454-4a81-b658-69c2da1c90a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "for logger in loggers:\n",
    "    if \"transformers\" in logger.name.lower():\n",
    "        logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f921208-c689-4c81-b68f-22c4922c67ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 0. autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50839d65-be00-4f76-8e12-c122b7b69d6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#code for autoreload script associated with jupyter notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7110737a-9a5a-40fb-b645-5c9cd28f652e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1.SETUP\t ENVIRONMENT VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6cae576-657f-403d-b4d4-e986af811158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import config\n",
    "from load_config import load_config\n",
    "\n",
    "model_name = 'bert-base-uncased'    # 'bert-base-uncased' ou 'deberta-large' or 'gemma'\n",
    "dataset    = 'agnews'               # 'movies' / 'agnews' / 'dbpedia' / 'medical'/ 'ledgar'/ n24news\n",
    "annotation = 'C3M'       # 'C3M' ou 'our_annotation' ou 'combined_annotation'\n",
    "config = load_config(model_name, dataset)\n",
    "config.annotation = annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35cdb74e-0d6f-4e0c-bfb4-18a7d429ae21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. Data Loading and Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce71d055-69ce-4c9c-9c55-f7a6d6fb0614",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import the data\n",
    "from data_agnews import prepare_agnews_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des fichiers sauvegardés...\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, val_loader, train_df, val_df, test_df = prepare_agnews_data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f964f317-66b6-4965-ae00-74592c7586cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3. Launching experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b91ac0e8-3410-41d6-9c91-d7b52c896ec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import pipeline\n",
    "from concepts_discovery_utils import (\n",
    "    extract_target_words, create_context_window,\n",
    "    load_model, run_concepts_discovery, calculate_macro_concept_frequencies,\n",
    "    update_concept_frequencies, find_most_frequent_macro_concept,\n",
    "    \n",
    " ) #summarize_concepts, \n",
    "from attribution_utils import (\n",
    "    process_data_in_batches, get_example, example_attribution,\n",
    "    split_dataloader\n",
    ")\n",
    "import json\n",
    "\n",
    "# Ranking concepts \n",
    "from ranking_utils import rank_macro_concepts, most_k_important_macro_concepts, get_concept_at_rank, randomize_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a400d91-ab31-4637-a384-5ea397363aa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Launch experimentation for OUR pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.model_name == 'gemma':\n",
    "    from full_pipeline_gemma import JointResidualFittingModel\n",
    "    from models.jointCBMv2_gemma import JointModel\n",
    "else:\n",
    "    from full_pipeline import JointResidualFittingModel\n",
    "    from models.jointCBMv2 import JointModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9526898a-264e-4ee1-976d-b586bc804a38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Load the joint model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83b3f528-ec20-4b85-9a5b-44d8a64dde6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "embedder_model, embedder_tokenizer, ModelXtoCtoY_layer, _ = load_model_and_tokenizer(config, n_concepts = 1)\n",
    "CBM_joint = JointModel(embedder_model, embedder_tokenizer, ModelXtoCtoY_layer, config, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "223e2b5b-23a8-439a-a6b8-462bec186a33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.call of the residual fitting part for pipeline below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59e68e65-b6d3-4ace-b6ec-57c5a25f4ebc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from models.utils import RidgeLinearLayer\n",
    "\n",
    "# residual fitting part for pipeline below\n",
    "linear_layer = RidgeLinearLayer(config.dim, config.num_labels, l2_lambda=0.01)\n",
    "linear_layer.to(config.device)\n",
    "\n",
    "CBM_joint.linear_layer = linear_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01d4326d-91ea-4cbc-8aac-2fa068f584ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Instancie the pipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caafeefa-cfc5-4d2d-b443-ecdbc48dc0e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "joint_residual_model = JointResidualFittingModel(\n",
    "    joint_model = CBM_joint,\n",
    "    linear_layer = linear_layer, \n",
    "    discovery_model = None, \n",
    "    discovery_tokenizer = None,\n",
    "    config = config\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "370f69f5-33f2-48ce-a3f8-918eb59853c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. launch the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  new dataset C3M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the dataframe\n",
    "from prepare_data import prepare_data_from_csv\n",
    "df_aug_train, df_aug_test = prepare_data_from_csv(annotation  = config.annotation, config = config, return_test = True)\n",
    "\n",
    "# # dataloaders\n",
    "from concepts_bank_utils import create_dataloader\n",
    "notre_loader_train = create_dataloader(df_aug_train, embedder_tokenizer, config.max_len, config.batch_size)\n",
    "notre_loader_test = create_dataloader(df_aug_test, embedder_tokenizer, config.max_len, config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation study : random importance score launch 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# 1) Répertoires et noms\n",
    "base_ckpt = Path(config.SAVE_PATH) / \"blue_checkpoints\" / config.model_name / \"cavs\" / config.cavs_type\n",
    "our_ckpt  = Path(config.SAVE_PATH) / \"blue_checkpoints\" / config.model_name / \"Our_CBM_joint\"\n",
    "our_ckpt.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for run in range(10):\n",
    "    print(f\"\\n=== RUN {run} ===\")\n",
    "    # 2) Copier le coverage_evolution MJ_{run}.pkl vers le nom standard attendu\n",
    "    src_pkl = base_ckpt / f\"sorted_macro_concepts_coverage_MJ_{config.annotation}_{config.agg_mode}_{config.agg_scope}_{run}.pkl\"\n",
    "    dst_pkl = base_ckpt / f\"sorted_macro_concepts_coverage_MJ_{config.annotation}_{config.agg_mode}_{config.agg_scope}.pkl\"\n",
    "    shutil.copy(src_pkl, dst_pkl)\n",
    "\n",
    "    # TODO: delete this lien after\n",
    "    config.num_epochs = 10\n",
    "    \n",
    "    # 3) Créer un dossier pour ce run\n",
    "    run_dir = our_ckpt / f\"run_{run}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 4) Instancier et lancer la pipeline\n",
    "    from models.jointCBMv2 import JointModel\n",
    "    from models.utils       import RidgeLinearLayer\n",
    "    embedder_model, embedder_tokenizer, ModelXtoCtoY_layer, _ = load_model_and_tokenizer(\n",
    "        config, n_concepts=1\n",
    "    )\n",
    "    CBM_joint = JointModel(\n",
    "        embedder_model,\n",
    "        embedder_tokenizer,\n",
    "        ModelXtoCtoY_layer,\n",
    "        config,\n",
    "        train_loader,\n",
    "        val_loader\n",
    "    )\n",
    "    linear_layer = RidgeLinearLayer(config.dim, config.num_labels, l2_lambda=0.01).to(device)\n",
    "    joint_residual_model = JointResidualFittingModel(\n",
    "        joint_model=CBM_joint,\n",
    "        linear_layer=linear_layer,\n",
    "        discovery_model=None,\n",
    "        discovery_tokenizer=None,\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    joint_residual_model.run_full_pipeline_tcavs_strategy(\n",
    "        train_loader=notre_loader_train,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=notre_loader_test,\n",
    "        num_iterations=10,\n",
    "        num_epochs_residual_layer=5,\n",
    "        cavs_type_arg=config.cavs_type,\n",
    "        strategy=\"new_heuristique_MJ\",\n",
    "        coverage_threshold=95\n",
    "    )\n",
    "\n",
    "    strategy=\"new_heuristique_MJ\"\n",
    "    \n",
    "    # 5) Copier tous les .pth intermédiaires dans run_dir\n",
    "    #    ils sont déposés dans our_ckpt, on glob par pattern strategy+iteration\n",
    "    pattern = (\n",
    "        our_ckpt /\n",
    "        f\"{config.model_name}_*.pth\"\n",
    "    )\n",
    "    for src in glob.glob(str(pattern)):\n",
    "        shutil.copy(src, run_dir / Path(src).name)\n",
    "    \n",
    "    pattern = (\n",
    "        our_ckpt /\n",
    "        f\"{config.model_name}_*.pth\"\n",
    "    )\n",
    "    for src in glob.glob(str(pattern)):\n",
    "        shutil.move(src, run_dir / Path(src).name)\n",
    "    \n",
    "    # 6) Copier le JSON de perf\n",
    "    src_perf = our_ckpt / f\"{config.model_name}_performance_{strategy}.json\"\n",
    "    dst_perf = run_dir / f\"{config.model_name}_performance_{strategy}_run{run}.json\"\n",
    "    shutil.move(src_perf, dst_perf)\n",
    "    \n",
    "    print(f\"✅ Run {run} terminé. Tous les artefacts sont dans {run_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moyenne +- ecart type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recalculer tous les test accuracy : cassetête chinois de ouf\n",
    "model_name = 'bert-base-uncased'\n",
    "dataset = 'movies'\n",
    "\n",
    "if model_name == 'bert-base-uncased':\n",
    "    if dataset == 'movies':\n",
    "        from config_movies import Config as Config_movies\n",
    "        config = Config_movies()\n",
    "        # import the data\n",
    "        from data_movies import prepare_movies_data\n",
    "        train_loader, test_loader, val_loader, train_df, val_df, test_df = prepare_movies_data(config)\n",
    "\n",
    "    elif dataset =='agnews':\n",
    "        from config_agnews import Config as Config_agnews \n",
    "        config = Config_agnews()\n",
    "        # import the data\n",
    "        from data_agnews import prepare_agnews_data\n",
    "        train_loader, test_loader, val_loader, train_df, val_df, test_df = prepare_agnews_data(config)\n",
    "\n",
    "    elif dataset == 'dbpedia':\n",
    "        from config_dbpedia import Config as Config_dbpedia \n",
    "        config = Config_dbpedia()\n",
    "        # import the data\n",
    "        from data_dbpedia import prepare_dbpedia_data\n",
    "        train_loader, test_loader, val_loader, train_df, val_df, test_df = prepare_dbpedia_data(config)\n",
    "\n",
    "    # elif dataset =='medical':\n",
    "    #     from config_medical import Config as Config_medical\n",
    "    #     config = Config_medical()\n",
    "    #     # import the data\n",
    "    #     from data_medical import prepare_medical_data\n",
    "    #     train_loader, test_loader, val_loader, train_df, val_df, test_df = prepare_medical_data(config)\n",
    "\n",
    "    else :\n",
    "        print('enter a valid dataset name')\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# charger les données \n",
    "from concepts_bank_utils import create_dataloader\n",
    "\n",
    "embedder_model, embedder_tokenizer, ModelXtoCtoY_layer, _ = load_model_and_tokenizer(config, n_concepts = 1)\n",
    "\n",
    "# charger les données de train\n",
    "df_aug_train = pd.read_csv(f\"{config.SAVE_PATH_CONCEPTS}/df_with_topics_v4_C3M.csv\")\n",
    "\n",
    "# adapt lines of code above to replace train_data and test_data by df_aug_train & df_aug_test\n",
    "df_aug_train['text'] = df_aug_train['text'].astype(str).str.strip()\n",
    "\n",
    "if(df_aug_train['label'].dtype != int):\n",
    "    df_aug_train['label'] = df_aug_train[\"label\"].astype(str).str.strip()\n",
    "\n",
    "#dataset length\n",
    "print(\"df_aug_train\", len(df_aug_train))\n",
    "print(df_aug_train['label'].unique())\n",
    "\n",
    "# import json file\n",
    "with open(f\"{config.SAVE_PATH_CONCEPTS}/dictionary_{config.DATASET}.json\", \"r\") as f:\n",
    "    caption_to_number = json.load(f)\n",
    "\n",
    "print(caption_to_number)\n",
    "\n",
    "if(df_aug_train['label'].dtype != int):\n",
    "    df_aug_train = df_aug_train[df_aug_train[\"label\"].isin(caption_to_number.keys())]\n",
    "    df_aug_train[\"label\"] = df_aug_train[\"label\"].map(caption_to_number)\n",
    "\n",
    "print(\"df_aug_train\", len(df_aug_train))\n",
    "print(df_aug_train['label'].unique())\n",
    "\n",
    "# determine total number of concepts\n",
    "columns_CBM = [col for col in df_aug_train.drop(columns=['Unnamed: 0','text','label']) if 'dummy' in col]\n",
    "columns_C3M = [col for col in df_aug_train.drop(columns=['Unnamed: 0','text','label']) if not 'dummy' in col]\n",
    "n_concepts = len(columns_C3M)\n",
    "print(\"..n_concepts\", n_concepts)\n",
    "print(columns_C3M)\n",
    "\n",
    "# test on C3M smaller dataset (1000 instances) for concept accuracy\n",
    "df_aug_test = pd.read_csv(f\"{config.SAVE_PATH_CONCEPTS}/df_with_topics_v4_test_C3M.csv\")\n",
    "\n",
    "# adapt lines of code above to replace train_data and test_data by df_aug_train & df_aug_test\n",
    "df_aug_test['text'] = df_aug_test['text'].astype(str).str.strip()\n",
    "if(df_aug_test['label'].dtype != int):\n",
    "    df_aug_test['label'] = df_aug_test[\"label\"].astype(str).str.strip()\n",
    "\n",
    "#dataset length\n",
    "print(\"df_aug_test\", len(df_aug_test))\n",
    "print(df_aug_test['label'].unique())\n",
    "\n",
    "print(caption_to_number)\n",
    "\n",
    "if(df_aug_test['label'].dtype != int):\n",
    "    df_aug_test = df_aug_test[df_aug_test[\"label\"].isin(caption_to_number.keys())]\n",
    "    df_aug_test[\"label\"] = df_aug_test[\"label\"].map(caption_to_number)\n",
    "\n",
    "print(\"df_aug_test\", len(df_aug_test))\n",
    "print(df_aug_test['label'].unique())\n",
    "\n",
    "# clean column names\n",
    "df_aug_test.columns = [\"dummy_\"+col.replace(\"\\n\", \"\").strip() if col in columns_C3M else col.replace(\"\\n\", \"\").strip() for col in df_aug_test]\n",
    "\n",
    "# clean types to int for \"missing values\"\n",
    "for col in [col for col in df_aug_test.columns if (df_aug_test[col].dtype == 'O') and (col !='text') and (col!='label')]:\n",
    "   # df_aug_test[col] = df_aug_test[col].apply(safe_int_convert)\n",
    "    df_aug_test[col] = df_aug_test[col].apply(lambda x: int(x) if str(x).isdigit() else 0)\n",
    "\n",
    "# dataloaders\n",
    "notre_loader_test = create_dataloader(df_aug_test, embedder_tokenizer, config.max_len, config.batch_size)\n",
    "\n",
    "# 1 recuperer le meilleur modèle charger \n",
    "\n",
    "# 1) Pattern pour trouver tous les JSON de performance\n",
    "pattern = f\"{config.SAVE_PATH}/blue_checkpoints/{config.model_name}/Our_CBM_joint/run_*/*.json\"\n",
    "files = sorted(glob.glob(pattern))\n",
    "\n",
    "# 2) Extraction des métriques\n",
    "records = []\n",
    "for path in files:\n",
    "    # on récupère le numéro de run depuis le nom de dossier\n",
    "    m = re.search(r\"run_(\\d+)\", path)\n",
    "    run_id = int(m.group(1)) if m else None\n",
    "\n",
    "    # on ouvre le JSON\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    if len(data['test_metrics']) > 1: \n",
    "        from models.jointCBMv2 import JointModel\n",
    "        \n",
    "        device = config.device\n",
    "        iteration = len(data['test_metrics']) - 1\n",
    "        n_concept_start = len(data['concepts_discovered_by_iteration'])\n",
    "        # load le modèle\n",
    "        from models.jointCBMv2 import JointModel\n",
    "        embedder_model, embedder_tokenizer, ModelXtoCtoY_layer, _ = load_model_and_tokenizer(config, n_concepts = n_concept_start)\n",
    "        strategy = \"new_heuristique_MJ\"\n",
    "        PATH_embedder = f\"{config.SAVE_PATH}blue_checkpoints/{config.model_name}/Our_CBM_joint/run_{run_id}/{config.model_name}_embedder_state_dict_{strategy}_{iteration}.pth\"\n",
    "        PATH_ModelXtoCtoY_layer = f\"{config.SAVE_PATH}blue_checkpoints/{config.model_name}/Our_CBM_joint/run_{run_id}/{config.model_name}_ModelXtoCtoY_layer_state_dict_{strategy}_{iteration}.pth\"\n",
    "        \n",
    "        \n",
    "        embedder_model.load_state_dict(torch.load(PATH_embedder))\n",
    "        ModelXtoCtoY_layer.load_state_dict(torch.load(PATH_ModelXtoCtoY_layer))\n",
    "        \n",
    "        embedder_model.to(device)\n",
    "        embedder_model.eval()\n",
    "        \n",
    "        CBM_joint_ = JointModel(embedder_model, embedder_tokenizer, ModelXtoCtoY_layer, config, None, None)\n",
    "        CBM_joint_.concepts_name = data['concepts_discovered_by_iteration']\n",
    "        print(\".._model_.cavs.shape\", len(CBM_joint_.concepts_name))\n",
    "        print(\"..n_model_.classifier\", CBM_joint_.ModelXtoCtoY_layer)\n",
    "\n",
    "        # evaluate le model sur test_loader\n",
    "\n",
    "        test_metrics_acc = CBM_joint_.evaluate_model(test_loader, 'test', metrics_on_concepts = False)\n",
    "        test_metrics_metrics = CBM_joint_.evaluate_model(notre_loader_test, 'test', metrics_on_concepts = True)\n",
    "\n",
    "        # recuperer le task_global_accuracy_ d'ici\n",
    "\n",
    "        acc = test_metrics_acc[\"task_global_accuracy\"]\n",
    "        f1  = test_metrics_metrics[\"mean_concept_f1_score\"]\n",
    "        n_concepts = n_concept_start\n",
    "        \n",
    "    else:\n",
    "        # on suppose que `data['test_metrics']` est une liste de dicts\n",
    "        # et qu’on s’intéresse à la dernière itération\n",
    "        last = data[\"test_metrics\"][-1]\n",
    "        acc = last[\"task_global_accuracy\"]\n",
    "        f1  = last[\"mean_concept_f1_score\"]\n",
    "        n_concepts = len(data['concepts_discovered_by_iteration'])\n",
    "\n",
    "\n",
    "    records.append({\n",
    "        \"run\": run_id,\n",
    "        \"test_acc\": acc,\n",
    "        \"mean_concept_f1\": f1,\n",
    "        \"n_concepts\": n_concepts\n",
    "    })\n",
    "\n",
    "# 3) Construction du DataFrame\n",
    "df = pd.DataFrame(records).sort_values(\"run\").reset_index(drop=True)\n",
    "print(df)\n",
    "\n",
    "# 4) Calcul de la moyenne ± écart-type\n",
    "acc_mean, acc_std = df[\"test_acc\"].mean(), df[\"test_acc\"].std()\n",
    "f1_mean,  f1_std  = df[\"mean_concept_f1\"].mean(), df[\"mean_concept_f1\"].std()\n",
    "n_concepts_mean,  n_concepts_std  = df[\"n_concepts\"].mean(), df[\"n_concepts\"].std()\n",
    "\n",
    "print(f\"\\nTest Accuracy : {100*acc_mean:.2f} ± {100*acc_std:.2f}\")\n",
    "print(f\"Mean Concept F1: {100*f1_mean:.2f} ± {100*f1_std:.2f}\")\n",
    "print(f\"Mean Number of concepts: {n_concepts_mean:.2f} ± {n_concepts_std:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "# fin\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4_Joint_Incremental_CBM_notebook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python (yann_kernel)",
   "language": "python",
   "name": "yann_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
